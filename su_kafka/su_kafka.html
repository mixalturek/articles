<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <title>su kafka</title>

    <style media="all">
        body { background-color: silver; font-family: sans-serif; text-align: justify; line-height: 1.4em; }
        #page { margin: auto; width: 90em; background-color: white; padding: 2em; border: 1px solid black; }
        .img { text-align: center; }
        pre { border: 1px solid gray; padding: 1em; }
    </style>
</head>

<body>
<div id="page">

<h1>su kafka</h1>

<p>Tento příběh začal, jako většina podobných investigací, příchozími alerty o chybách na produkci. Pravidelně spouštěné integrační testy začaly po aktualizaci a restartu jednoho z nodů Apache Kafka clusteru ve frankfurtském datacentru hlásit duplikace v konzumovaných zprávách.</p>

<p>V naší konfiguraci taková situace kvůli timeoutům a následným pokusům o opětovné odeslání může občas (zřídka) nastat a v dostatečně malém množství nám nevadí, nicméně všechno má své meze. Pokud není množství chyb v poměru k celkovému počtu událostí statisticky významné, není třeba nic řešit. Ale je velký rozdíl, pokud nastanou jednotky až stovky duplicit denně, nebo jestli jich jsou tisíce za vteřinu po dobu několika hodin. Byl to zkrátka takový ošklivý... nepěkná věc, která se už neututlá a raději se s ní jde rovnou ven, protože by si jí stějně někdo brzy všimnul.</p>

<p>Začátek problémů celkem jasně korespondoval s aktualizací jednoho Kafka brokeru z 0.10.1.1 na 0.10.2.1 a následným restartem. Zkušenosti s rolling restartem Kafky říkají, že se jedná o spíše křehkou operaci, při které se dost často něco po... pokazí a pokaždé nějak úplně jinak. Kreativita distribuovaných systémů dokáže vždy překvapit. Pokud máte s graceful restarty Kafky jiné a lepší zkušenosti, čtěte dál, přesně o tom je tento článek. My už je snad budeme mít také.</p>


<h2>Systém z výšky jednoho kilometru</h2>

<p>Náš systém pro analýzu dat má především kvůli možnosti škálovat do datacenter dvě vrstvy oddělených Kafka clusterů. Přijímací Kafka běží ve čtyřech datacentrech rozložených různě po světě. Zapisuje do nich Receiver, což je v podstatě REST-like proxy pro Kafka producer, který mimo jiné do událostí vyplňuje IP adresy protistrany a čas příjmu dat. Kafka slouží jako distribuovaný perzistentní log. Ve chvíli, kdy je do ní libovolná zpráva uložena, máme několik dnů na její vykonzumování a zpracování. Receiver a DC Kafka jsou tedy základem stability systému a musí vždy spolehlivě běžet.</p>

<p>Události z Kafky vyčítají Input Filtry, jejichž úkolem je konverze starších formátů na nový, čištění dat, opravy chyb způsobených bugy v klientech, doplnění GeoIP informací a podobně. Data se zapisují zpět do stejné DC Kafky, ale do jinak pojmenovaných topiků.</p>

<p>Vyčištěné události se z DC Kafka clusterů mirrorují pomocí standartního Mirror maker toolu do master Kafky, odkud události vyčítají finální konzumeři do Hadoopu/HDFS, do Elastic Searche, popř. se jedná o stream processing.</p>

<p class="img"><img src="img/kafka_pipeline.png" /></p>


<h2>Duplicity, duplicity, duplicity</h2>

<p>Integrační testy, o nichž byla v úvodu řeč, simulují chování reálných klientů na obou stranách Kafka pipeline. Generují a zapisují události do Receiverů v jednotlivých datacentrech, následně je vyčítají z master Kafky a porovnávají přijatá data s očekávanými transformacemi. Každá z testovacích zpráv obsahuje unikátní UUID.randomUUID() pro zpárování vstupu a výstupu, bez toho by nemohly fungovat. Integrační testy si ale také ukládají množinu již přijatých UUID. Pokud se některé z nich na výstupu systému objeví dvakrát, je to jasná známka duplikace, ať už vznikla kdekoli.</p>

<p>Jelikož počátek duplikací časově korespondoval s restartem Kafka brokeru ve franskfurtském datacentru, dalo se předpokládat, že je na vině některý ze systémů, který přímo komunikuje s Kafkou, tj. Receiver (producer), Filtry (konsumer, producer), ostatní Kafka brokeři ve frankfurtu (repliky) nebo Mirror maker (konzumer).</p>

<p>Jako viník byl nakonec podle grafů odhalen Mirror maker, kterému se v daném čase skokově zvýšil počet zkonzumovaných zpráv. V globálním pohledu to není tak zřejmé, ale při zaostření pouze na Frankfurkt bylo vše ihned jasné. Stačil jednoduchý restart procesu a trafik se opět skokově snížil na původní hodnutu a integrační testy se znovu samým štěstím zazelenaly.</p>

<p class="img"><img src="img/duplicates_mirrors_all.png" /></p>
<p class="img"><img src="img/duplicates_mirrors_fra.png" /></p>

<p>Poznámka na okraj pro úplnost článku: Chybu v Mirror makeru a potažmo v libovolném Kafka konzumeru jsme nedokázali vystopovat. Na základě logů jsme měli několik teorií, ale všechny jsme bohužel dokázali celkem snadno vyvrátit. Bug report do Kafky nemělo cenu vytvářet, protože jsme neměli žádné vodítko, kterým směrem obrátit pozornost Kafka vývojářů. Ti jsou mimochodem velice aktivní a odpovídají prakticky okamžitě, už jsme pár chyb v minulosti hlásili.</p>


<h2>Zabíjíme Kafku</h2>

<p>Proč jsou restarty Kafky vždycky tak křehké jako napůl vysušený hrad z písku? A proč to nikdo jiný než my neřeší? Tohle přece musí vadit každému. Žádný ticket, žádný článek, žádný blog.</p>

<p>Chvíle ticha...</p>

<p>A co když je problém jenom u nás na serverech? Když spouštím Kafku u sebe při vývoji, je typicky všechno v pořádku. Ale je pravda, že u mě neteče třicet tisíc zpráv za vteřinu, může být rozdíl v tom? Pojďme to už jednou provždy vyřešit!</p>

<p>Pozorované symptomy</p>

<ul>
<li>Kafka po restartu vždy přepočítává spousty koruptovaných souborů s indexy. Tato operace běžně trvá i <strong>několik hodin</strong> a opravdu bolí. Jeden rolling restart celého clusteru trvá běžně celý den. Update na novou verzi potřebuje v obecném případě dva restarty a clusterů máme několik. Zkrátka obrovské au.</li>
<li>Pokud se Kafka po zastavení hned spustí, ZooKeeper ji odmítne, protože si myslí, že stále běží. Broker ID  je stále registrované a je třeba chvíli počkat na timeout.</li>
<li>Producerům se v okamžiku restartu nedaří zapisovat do partition, jejichž leader je při rebalancingu migrován na ostatní brokery z ISR (In Sync Replicas). Callback v klientu obdrží výjimku místo úspěšného potvrzení, nakonfigurovaný jeden retry nestačí.</li>
<li>Na producerech používáme <code>acks = 1</code>, tj. při odesílání dat stačí potvrzení leadera. Ve chvíli, kdy leader přestane být dostupný, se tudíž ztrácí zprávy, které ještě nebyly odeslány replikám. Řádově se jedná o desítky až stovky zpráv.</li>
<li>Konzumeři se občas škaredě zblázní. A když říkám škaredě, myslím tím opravdu <strong>škaredě</strong>. Výše jsou popsané duplikace, ale už jsme u několika mála partition a konzumer grup viděli i ztrátu offsetů, což by nemělo nikdy nastat. Podle logů byla pravděpodobně způsobená chvilkovou nedostupností dat. Nevalidní offset při požadavku na data spolu s nevhodnou konfigurací <code>auto.offset.reset = earliest</code> způsobil skok na začátek logu a následnou bolestivou rekonzumaci všech dat, tj. posledních několik dnů. Od jisté doby už nepoužíváme earlieast, ale latest s všudypřítomným komentářem, že je lepší přeskočit a ztratit pár minut, než zbytečně všechno vyčítat a znovuzpracovávat. Samozřejmě záleží na službě a očekáváních.</li>
</ul>

<p class="img"><img src="img/mirror_lag.png" /></p>

<p>Vypadá to, jako bychom Kafku neukončovali korektně. V hlavě se nám objevuje slovo <code>SIGKILL</code>, ale kdo by ho posílal?</p>


<h2>Ukončujeme Kafku</h2>

<p>Nyní jsou dvě možné varianty, buď máme Kafku špatně nakonfigurovanou nebo ji ukončujeme špatně. <a href="http://kafka.apache.org/documentation/#basic_ops_restarting">Dokumentace o restartech</a> hovoří jasně.</p>

<ul>
<li>Vypínaný server synchronizuje všechny logy na disk, aby zamezil potřebě jakýchkoli oprav. Případné opravy trvají dlouho a pokud nejsou nutné, úmyslné restarty budou rychlejší.</li>
<li>Vypínaný server namigruje všechny partition, u kterých je veden jako leader, na ostatní repliky. Toto minimalizuje čas, kdy je partition nedostupná na několik milisekund.</li>
</ul>

<p>Synchronizace souborů na disk by měla být aktivní vždy nezávisle na konfiguraci, migrace leaderů, pouze pokud je v konfiguraci uvedeno <code>controlled.shutdown.enable = true</code>. V konfiguračním souboru tuto volbu máme uvedenou, takže problém by měl být někde jinde.</p>

<p>Jak správně ukončit Kafku? Skript <code>kafka-server-stop.sh</code> používá signál <code>SIGTERM</code>.</p>

<pre>
#!/bin/sh
# ...
PIDS=$(ps ax | grep -i 'kafka\.Kafka' | grep java | grep -v grep | awk '{print $1}')

if [ -z "$PIDS" ]; then
  echo "No kafka server to stop"
  exit 1
else.
  kill -s TERM $PIDS
fi
</pre>

<p>Direktivu <code><a href="http://upstart.ubuntu.com/cookbook/#kill-signal">kill signal</a></code> v Upstart konfiguraci explicitně uvedenou nemáme, nicméně výchozí hodnotou je předpokládaný <code>SIGTERM</code>. Pokud by se proces ale nestihl ukončit, Upstart by ho po <a href="http://upstart.ubuntu.com/cookbook/#daemon-behaviour">kill timeoutu (ve výchozím stavu 5 sekund) zabil signálem <code>SIGKILL</code></a>. Ha! Pět sekund je opravdu hodně málo a toto by mohla být příčina všech našich problémů. Konfigurace však explicitně uvádí <code>kill timeout 300</code>, což není žádných 5 sekund ale 5 minut. Autor zde byl opravdu štědrý a chtěl mít jistotu, že Kafka bude mít dost času. Na všech úrovních bychom tedy měli mít všechno nastaveno správně.</p>

<pre>
exec /bin/su -s /bin/sh - kafka -c '/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties'
# wait on stop (to fix restart) for two reasons
# 1) avoid jmx/rmi 'port already in use'
# 2) wait for the session to expire in ZK to avoid start-up fail
post-stop exec sleep 11
respawn
respawn limit 3 30

# http://upstart.ubuntu.com/wiki/Stanzas
# time to wait between sending TERM and KILL signals
kill timeout 300

start on stopped rc RUNLEVEL=[2345]
stop on runlevel [S016]
</pre>

<p>Kde by jenom mohla být chyba? Na světě není nic dokonalé, dokonce ani software, nějaký bug někde? Ale kde? :-(</p>

<p>Zkuste se zamyslet, než budete číst dál. Představte si, že jste se dostali k poslední stránce napínavé detektivky. Víte, že už máte všechny potřebné informace a logickou úvahou máte dojít k tomu, kdo je vrah. <strong>Kdo je tedy vrah?</strong> Kdo bez jakýchkoli rozpaků brutálně zabíjí Kafku signálem <code>SIGKILL</code>?</p>


<h2>su kafka</h2>

<p>Ano, správně. Je to někdo, kdo téměř ani nebyl zmíněn, téměř neviditelný pomocník <code>/bin/su</code>. Tento užitečný prográmek je asi nejznámější soubor se <code>sticky bitem</code> a bývá mnohokrát skloňován snad v každé knize o bezpečnosti v unixových prostředích (např. <a href="https://www.dwheeler.com/secure-programs/">Secure Programming HOWTO</a>). Pojďme v <code>/bin/su</code> zkusit najít odpověď na naši otázku.</p>

<p>Anketa: Zabíjí <code>/bin/su</code> potomka signálem <code>SIGKILL</code>?</p>

<ul>
<li>Ano.</li>
<li>Ne.</li>
<li>Jiné.</li>
<li>Nevím.</li>
</ul>


<p>V tomto případě se <code>/bin/su</code> nepoužívá k typickému zvyšování práv na roota, např. kvůli instalaci nového softwaru. Používá se přesně naopak, tedy ke snížení práv spouštěného procesu, aby Kafka neběžela pod rootem.</p>

</div>
</body>
</html>
