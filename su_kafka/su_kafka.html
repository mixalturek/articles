<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <title>Přání býti kafkou</title>

    <style media="all">
        body { background-color: silver; font-family: sans-serif; text-align: justify; line-height: 1.4em; }
        #page { margin: auto; max-width: 70%; background-color: white; padding: 2em; border: 1px solid black; }
        #perex { font-style: italic; }
        .img { text-align: center; overflow: auto; }
        pre { border: 1px solid gray; padding: 1em; background-color: #eeeeee; overflow: auto; }
        .highlight { font-weight: bold; color: orange; }
        div .side { border-left: 0.5em dotted gray; width: 70%; margin: auto; padding: 0.5em 2em 0.5em 2em; background-color: #eeeeee; }
    </style>
</head>

<body>
<div id="page">

<h1>Přání býti kafkou</h1>

<p id="perex">Když se jeden Linux admin a jeden backend vývojář rozhodnou vyzkoumat příčinu problému, který je pravidelně otravuje při restartech distribuované cloudové služby, můžou se postupně ponořit opravdu hluboko...</p>

<p>Tento příběh začal, jako většina podobných investigací, příchozími alerty o chybách na produkci. Pravidelně spouštěné integrační testy začaly po aktualizaci a plánovaném restartu jednoho z nodů <a href="http://kafka.apache.org/">Apache Kafka</a> clusteru hlásit duplikace v konzumovaných zprávách.</p>

<p>Nejsme banka, a tudíž v naší konfiguraci může taková situace občas (zřídka) nastat, nicméně všechno má své meze. Pokud není množství chyb v poměru k celkovému počtu událostí statisticky významné, není třeba nic řešit. Ale je velký rozdíl mezi desítkami až stovkami duplicit denně nebo tisíci za vteřinu po dobu několika hodin. Byl to zkrátka takový ošklivý... nepěkná věc, která se už neututlá a raději se s ní jde rovnou ven, protože by si jí stějně někdo brzy všimnul.</p>

<p>Začátek všech alertů celkem jasně korespondoval s aktualizací první instance Kafky a následným restartem. Naše dosavadní zkušenosti s rolling restarty Kafky říkají, že se jedná spíše o křehkou operaci, při které se dost často něco po... pokazí a pokaždé nějak úplně jinak. Kreativita distribuovaných systémů dokáže vždy překvapit. Pokud máte s graceful restarty Kafky jiné, lepší zkušenosti, čtěte dál, právě o tom je tento článek. My už je snad budeme mít v budoucnu také - <em>zkrátka chyba byla u nás a Kafka za nic nemohla</em>.</p>

<p>Během zpětné analýzy si osvěžíme principy operačních systémů, setkáme se s tucty známých i méně známých termínů, objevíme naprosto nečekané rozdíly v distribucích založených na RedHatu a Debianu a také se mimo jiné zanoříme do zdrojových kódů jistého unixového nástroje, který lidstvo denně používá už desítky let. Text se může zdát místy trochu složitější, ale nenechte se odradit, čtení až do konce bude určitě stát za to.</p>

<p>Aby čtenář pochopil, jak vysoko se na aplikačním stacku běžně pohybujeme a jak hluboko do operačního systému jsme se přes všechny vrstvy se svými analýzami následně dostali, je třeba nejdříve nastínit, jak vypadá architektura celého řešení.</p>


<h2>Z výšky jednoho kilometru</h2>

<p>Námi vyvinutý systém pro <em>big data</em> analýzy (v každodenních špičkách řádově 100k událostí/s, nekomprimovaných 100 MB/s) používá na příjmové straně dvě vrstvy oddělených Kafka clusterů. První skupina backendů toho času běží ve čtyřech nezávislých datacentrech rozmístěných různě po světě. Je to kvůli tomu, aby byly co nejblíže aplikacím u uživatelů, které produkují události, a zároveň aby dokázaly překlenout nejrůznější síťové nedostupnosti a nespolehlivosti Internetu.</p>

<p>Do Kafka clusterů proudí vstupní data výhradně skrz aplikaci <em>Receiver</em>, jedná se v podstatě o REST-like proxy obsahující Kafka producent klienta a nepříliš složitou logiku. Ve chvíli, kdy Kafka potvrdí příjem události, máme v případě možných problémů teoreticky až několik dnů na opravu, znovuvyčtení a zpracování uložených dat. Taková situace by rozhodně nebyla příjemná a určitě bychom se zapotili, nicméně by nemělo dojít k žádné ztrátě událostí. Receiver a Kafka jsou tedy základem stability celého systému a musí vždy spolehlivě běžet.</p>

<p>Události z Kafky vyčítají <em>Input Filtry</em>, jejichž úkolem je konverze starších formátů na nový, čištění dat, opravy chyb způsobených bugy v historických verzích klientů, obohacení událostí o GeoIP lokace a podobně. Data se zapisují zpět do té samé DC Kafky, ale do topiků s jinými jmény.</p>

<p>Vyčištěné události se z DC Kafka clusterů mirrorují pomocí standartního Mirror maker toolu do tzv. master Kafky, odkud je dále vyčítají finální konzumenti do <a href="http://hadoop.apache.org/">Hadoopu/HDFS</a>, vybrané topiky tečou do <a href="https://www.elastic.co/">Elasticsearche</a>, malá frakce se sampluje na stage a dev prostředí, popř. nad streamem běží nejrůznější realtime analýzy. Kafka otevírá spoustu možností.</p>

<p class="img"><img src="img/kafka_pipeline.png" /></p>

<p>Každá z aplikací běží replikovaně v několika instancích. Pro rychlou představu: Receiverů a Input Filtrů je 11, Kafka brokerů celkem 14, v rámci každého Kafka clusteru musí samozřejmě běžet i cluster <a href="https://zookeeper.apache.org/">ZooKeeperů</a>. Data z každého datacentra kopíruje 5 instancí Mirror makerů. Všichni konzument klienti se dále replikují nejen na úrovni instancí a strojů, ale, aby se zvýšil paralelismus, i pomocí konfigurovatelného počtu aplikačních vláken. Objem zpracovávaných dat s připojováním a rozšiřováním jednotlivých aplikací v čase neustále narůstá. Základním požadavkem je možnost snadného škálování na všech úrovních, jinak by systém už dávno nebyl udržitelný.</p>

<p>A v této změti distribuovaných aplikací, jejich jednotlivých instancí, strojů, aplikačních vláken, grafů a logů je třeba najít příčinu jisté zřídka se vyskytující chyby...</p>

<div class="side">
<h3>Apache Kafka</h3>
<p><a href="http://kafka.apache.org/">Apache Kafka</a> je platforma pro streamování dat. Sestává z distribuované serverové služby a dvojice klientských knihoven umožňujících produkci a konzumaci událostí. Veškeré záznamy drží na pevných discích typicky po dobu jednotek dní a zároveň je replikuje do několika instancí pro případ selhání některé z nich. Horizontálně škáluje.</p>

<p>Ačkoli data ukládá na disk, rozhodně není pomalá. Sekvenční čtení/zápis většího množství bufferovaných dat z/na disk je rychlostně srovnatelný s přístupem do paměti. Kafka dále využívá <a href="http://kafka.apache.org/documentation/#maximizingefficiency">různé triky</a> jako například přímé kopírování z disku na síťovou kartu v kernel space. Tím se obchází zbytečné kopírování bufferů do user space a zpět. Autor článku už několikrát ve čtyř-nodovém clusteru pozoroval datové přenosy stovek MB/s, resp. vyšších stovek tisíc zpráv/s. Limitním faktorem bývá spíše rychlost síťových propojů než disků nebo aplikačního kódu.</p>

<p>V nejjednodušší formě se Kafka používá k oddělení aplikací produkujících události od aplikací, které je zpracovávají. Producenti a konzumenti jsou naprosto nezávislé systémy a mají plně oddělený životní cyklus, spojuje je pouze formát přenášených zpráv.</p>

<p>Kafka bývá často srovnávána s messaging systémy typu <a href="https://www.rabbitmq.com/">RabbitMQ</a>. Narozdíl od nich garantuje pořadí doručení událostí - v jádru své architektury obsahuje datovou strukturu <a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">log</a>. Díky tomuto napohled malému rozdílu může být jednou z jejích dalších aplikací i <a href="https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/">primární databáze systému</a>, kdy tradiční databáze a úložiště (relační SQL databáze, <a href="http://hadoop.apache.org/">Hadoop</a>, <a href="https://www.elastic.co/">Elasticsearch</a>, <a href="http://cassandra.apache.org/">Cassandra</a>, <a href="https://redis.io/">Redis</a>, atd.) mají pouze formu <em>materialized view</em> a dají se kdykoli přepočítat.</p>
</div>

<h2>Duplicity, duplicity, duplicity</h2>

<p>Integrační testy, o nichž byla v úvodu řeč, simulují chování reálných klientů na obou stranách pipeline. Generují a zapisují události do Receiverů v jednotlivých datacentrech, následně je vyčítají z master Kafky a porovnávají přijatá data s očekávanými transformacemi. Každá z testovacích zpráv obsahuje unikátní <code>UUID.randomUUID()</code> pro párování vstupu a výstupu, bez toho by nemohly fungovat. Integrační testy si ale také ukládají množinu již přijatých UUID. Pokud se některé z nich na výstupu systému objeví více než jednou, je to jasná známka duplikace.</p>

<p>Jelikož počátek duplikací časově korespondoval s restartem prvního Kafka brokeru ve frankfurtském datacentru, dá se předpokládat, že je na vině tato DC Kafka nebo některý ze systémů, který s ní přímo komunikuje, tj. Receiver (producent), Input Filtry (konzument, producent), ostatní Kafka brokeři ve frankfurtu (repliky) nebo Mirror maker (konzument).</p>

<p>Jako viník byl nakonec podle grafů odhalen Mirror maker, kterému se v daném čase skokově zvýšil počet zkonzumovaných zpráv. V globálním pohledu to není tak zřejmé, ale při zaostření pouze na Frankfurkt bylo vše ihned jasné. Po restartu se datový přenos vrátil zpět na původní hodnoty a integrační testy znovu samým štěstím zezelenaly.</p>

<p class="img"><img src="img/duplicates_mirrors_all.png" /></p>
<p class="img"><img src="img/duplicates_mirrors_fra.png" /></p>

<p>Poznámka na okraj pro úplnost článku: Chybu v Mirror makeru a potažmo v libovolném Kafka konzumentu jsme nedokázali vystopovat. Na základě logů jsme měli několik teorií, ale všechny jsme bohužel dokázali celkem snadno vyvrátit. Bug report do Kafky tedy nemělo cenu vytvářet, protože jsme neměli žádné vodítko, kterým směrem obrátit pozornost Kafka vývojářů. Ti jsou mimochodem velice aktivní a odpovídají prakticky okamžitě, už jsme pár chyb v minulosti hlásili.</p>


<h2>Zabíjíme Kafku</h2>

<p>Proč jsou restarty Kafky vždycky křehké jako napůl vysušený hrad z písku? A proč to nikdo jiný než my neřeší? Tohle přece musí vadit každému, ale nikde není k nalezení žádný ticket, žádný článek, žádný blog post, nic.</p>

<p>(Chvíle ticha...)</p>

<p>A co když se problém vyskytuje jenom u nás, na našich serverech? Při vývoji Kafku spouštíme v Dockeru na pracovních noteboocích a typicky bývá všechno v pořádku. Nicméně je pravda, že v tomto případě jí protékají oproti třiceti tisícům zpráv za sekundu pouze malé desítky. Může být rozdíl způsobený výrazně vyšším zatížením? Pojďme to už jednou provždy vyřešit!</p>

<p>Pozorované symptomy:</p>

<ul>
<li>Kafka po restartu vždy přepočítává spousty koruptovaných indexů. Tato operace občas trvá i <strong>několik hodin</strong> a opravdu bolí. Jeden rolling restart celého clusteru trvá běžně celý den. Update na novou verzi potřebuje v obecném případě dva restarty a clusterů máme několik. Zkrátka obrovské <em>auuu</em>.</li>
<li>Pokud se Kafka po zastavení ihned spustí, ZooKeeper ji odmítne, protože si myslí, že stále běží. Broker ID je v něm stále registrované a je třeba chvíli počkat na timeout. Do init skriptu vkládáme při restartu mezi start a stop oprace umělý sleep.</li>
<li>Producentům se v okamžiku restartu nedaří zapisovat do partition, jejichž leader je při rebalancingu migrován na ostatní brokery z ISR (In Sync Replicas). Callback v klientu obdrží místo úspěšného potvrzení výjimku, nakonfigurovaný jeden retry nestačí.</li>
<li>Na producentech používáme <code>acks = 1</code>, tj. při odesílání dat stačí potvrzení od leadera, aby se považovala za bezpečně uložená. Ve chvíli, kdy leader přestane být dostupný, se tudíž ztrácí zprávy, které se ještě nestihly odeslat replikám. Řádově se jedná o malé desítky až stovky zpráv.</li>
<li>Konzumenti se občas škaredě zblázní. A když píšu škaredě, myslím tím opravdu <strong>škaredě</strong>. Výše byl popsán problém s duplikacemi, ale už jsme u několika mála partition a skupin konzumentů viděli i ztrátu offsetů, což by nemělo nikdy, ale opravdu nikdy nastat. Podle logů byla tato ztráta pravděpodobně způsobená chvilkovou nedostupností dat, kdy Kafka nejspíše klientovi odpověděla aniž by byla plně inicializovaná. Nevalidní offset při požadavku na data spolu s nevhodnou konfigurací <code>auto.offset.reset = earliest</code> způsobil skok na začátek logu a následnou bolestivou rekonzumaci všech dat, tj. posledních několika dnů. Od jisté doby už nepoužíváme <code>earliest</code>, ale <code>latest</code> s všudypřítomným komentářem, že je lepší přeskočit a ztratit pár minut, než zbytečně všechno vyčítat, znovuzpracovávat a řešit, že všechna data máme v HDFS a dalších systémech dvakrát. Samozřejmě záleží na službě a očekáváních.</li>
</ul>

<p class="img"><img src="img/mirror_lag.png" /></p>

<p>Vypadá to, jako bychom Kafku neukončovali korektně. V hlavě se nám objevuje termín <code>SIGKILL</code>, ale kdo by ho posílal a proč?</p>


<h2>Ukončujeme Kafku</h2>

<p>Nyní jsou ve hře dvě varianty, buď máme Kafku špatně nakonfigurovanou nebo ji ukončujeme špatně. <a href="http://kafka.apache.org/documentation/#basic_ops_restarting">Dokumentace o plánovaných restartech</a> hovoří jasně:</p>

<ul>
<li>Vypínaný server synchronizuje všechny logy na disk, aby zamezil potřebě jakýchkoli oprav. Případné opravy trvají dlouho a pokud nejsou nutné, úmyslné restarty budou rychlejší.</li>
<li>Vypínaný server migruje všechny partition, u kterých je veden jako leader, na ostatní repliky. Toto minimalizuje čas, kdy je partition nedostupná na několik milisekund.</li>
</ul>

<p>Zavření všech otevřených souborů a jejich synchronizace na disk by měla být aktivní vždy nezávisle na konfiguraci, migrace leaderů, pouze pokud se v konfiguraci nachází <code>controlled.shutdown.enable = true</code>. V konfiguračním souboru tuto volbu máme uvedenou, takže problém by měl být někde jinde.</p>

<p>Jak správně ukončit Kafku? Skript <code>kafka-server-stop.sh</code> z distribuce Kafky používá signál <code>SIGTERM</code>.</p>

<pre>
#!/bin/sh
# ...
PIDS=$(ps ax | grep -i 'kafka\.Kafka' | grep java | grep -v grep | awk '{print $1}')
# ...
kill -s TERM $PIDS
</pre>

<p>Jako init daemon používáme Upstart. Direktivu <code><a href="http://upstart.ubuntu.com/cookbook/#kill-signal">kill signal</a></code> sice v konfiguraci explicitně uvedenou nemáme, nicméně výchozí hodnotou je předpokládaný <code>SIGTERM</code>. Pokud by se ale proces nestihl ukončit, Upstart by ho po <a href="http://upstart.ubuntu.com/cookbook/#daemon-behaviour">pětisekundovém timeoutu zabil signálem <code>SIGKILL</code></a>. Ha! Pět sekund je opravdu hodně málo a toto by mohla být příčina všech našich problémů. Konfigurace však explicitně uvádí <code>kill timeout 300</code>, což není žádných 5 sekund ale 5 minut. Autor konstanty zde byl opravdu štědrý a chtěl mít jistotu, že Kafka bude mít dost času - lepší si chvíli počkat.</p>

<pre>
<span class="highlight">exec /bin/su -s /bin/sh - kafka -c '/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties'</span>
# wait on stop (to fix restart) for two reasons
# 1) avoid jmx/rmi 'port already in use'
# 2) wait for the session to expire in ZK to avoid start-up fail
post-stop exec sleep 11
respawn
respawn limit 3 30

# http://upstart.ubuntu.com/wiki/Stanzas
# time to wait between sending TERM and KILL signals
<span class="highlight">kill timeout 300</span>

start on stopped rc RUNLEVEL=[2345]
stop on runlevel [S016]
</pre>

<p>Na všech úrovních bychom tedy měli mít všechno nastaveno správně. Kde by jenom mohla být chyba? Na světě není nic dokonalé, dokonce ani software, nějaký bug někde? Ale kde?</p>

<p>Než budete číst dál, zkuste se zamyslet. Představte si, že jste se dostali k poslední stránce napínavé detektivky. Víte, že už máte všechny potřebné informace a logickou úvahou máte dojít k tomu, kdo je vrah. <strong>Kdo je tedy vrah?</strong> Kdo bez jakýchkoli rozpaků brutálně zabíjí Kafku signálem <code>SIGKILL</code>?</p>


<div class="side">
<h3>Unix a procesy</h3>

<p>V operačních systémech založených na Unixu se programy spouštějí pomocí kernelových volání <code>fork()</code> a <code>exec()</code>.</p>

<p>Úkolem <code>fork()</code> je naklonovat současný proces do nového. Ten bude až na jedno číslo identický, jedná se o návratovou hodnotu funkce <code>fork()</code>. Rodičovský proces v ní obdrží identifikátor potomka a potomek nulu. Procesy se tak dozví, kým jsou, a v kódu se mohou dále rozhodnout, jaké operace budou vykonávat.</p>

<p>Volání <code>exec()</code> umožňuje nahradit současný kontext procesu něčím jiným. Z kopie předchozího procesu se tak stane úplně jiná aplikace.</p>

<pre>
<span style='color:#898887;'>// gcc -Wall -o forkexec forkexec.c</span>
<span style='color:#898887;'>// ./forkexec</span>

<span style='color:#006e28;'>#include </span><span style='color:#006e28;'>&lt;stdio.h&gt;</span>
<span style='color:#006e28;'>#include </span><span style='color:#006e28;'>&lt;unistd.h&gt;</span>
<span style='color:#006e28;'>#include </span><span style='color:#006e28;'>&lt;sys/wait.h&gt;</span>

<span style='color:#0057ae;'>int</span> main(<span style='color:#0057ae;'>int</span> argc, <span style='color:#0057ae;'>char</span>* argv[]) {
  pid_t pid = fork();

  <b>if</b> (pid == -<span style='color:#b08000;'>1</span>) {
    fprintf(stderr, <span style='color:#bf0303;'>&quot;Fork failed</span><span style='color:#924c9d;'>\n</span><span style='color:#bf0303;'>&quot;</span>);
    <b>return</b> <span style='color:#b08000;'>1</span>;
  } <b>else</b> <b>if</b> (pid == <span style='color:#b08000;'>0</span>) {
    printf(<span style='color:#bf0303;'>&quot;Child: pid %d</span><span style='color:#924c9d;'>\n</span><span style='color:#bf0303;'>&quot;</span>, getpid());
    execl(<span style='color:#bf0303;'>&quot;/bin/echo&quot;</span>, <span style='color:#bf0303;'>&quot;/bin/echo&quot;</span>, <span style='color:#bf0303;'>&quot;Child: Hello, world!&quot;</span>, NULL);
    <b>return</b> <span style='color:#b08000;'>42</span>; <span style='color:#898887;'>// Never executed</span>
  } <b>else</b> {
    printf(<span style='color:#bf0303;'>&quot;Parent: pid %d, child %d</span><span style='color:#924c9d;'>\n</span><span style='color:#bf0303;'>&quot;</span>, getpid(), pid);
    <span style='color:#0057ae;'>int</span> status;
    waitpid(pid, &amp;status, <span style='color:#b08000;'>0</span>);
    printf(<span style='color:#bf0303;'>&quot;Parent: child exited %d</span><span style='color:#924c9d;'>\n</span><span style='color:#bf0303;'>&quot;</span>, status);
    <b>return</b> <span style='color:#b08000;'>0</span>;
  }
}
</pre>

<pre>
./forkexec
Parent: pid 9574, child 9575
Child: pid 9575
Child: Hello, world!
Parent: child exited 0
</pre>

<p>Procesy se v systému označují unikátním identifikátorem PID (Process ID). Platné hodnoty začínají číslem 1 a končí konstantou definovanou v <code>/proc/sys/kernel/pid_max</code>, která má typicky hodnotu 32768 popř. 4194303. Procesy se organizují do stromové struktury, prvním spuštěným je tzv. <code>init</code> s PID 1 (System V init, Upstart, SystemD a další) a má speciální povinnosti.</p>

<p>Volání <code>fork()</code> a <code>exec()</code> se nemusí používat pouze společně. Pokud by se zavolal pouze <code>exec()</code>, nedošlo by k naklonování procesu a spuštěná aplikace by se pouze nahradila nějakou jinou. Přesně toho chceme dosáhnout při spouštění Kafky.</p>

<p>V případě samostatného volání <code>fork()</code> by se v potomku nenahradil současný kontext za jiný a v systému by defakto běžely dvě kopie původního procesu. Toho se využívá například ve webových serverech, kdy rodičovský proces vytváří skupinu tzv. worker procesů, kterým přeposílá práci.</p>
</div>


<h2><code>su kafka</code></h2>

<p>Kdo je tedy vrah? Ano, správně. Je to někdo, kdo téměř ani nebyl zmíněn, téměř neviditelný pomocník <code>/bin/su</code>. Tento užitečný prográmek je asi nejznámější soubor s nastaveným <code>sticky bitem</code> a bývá často skloňován v knihách o bezpečnosti v unixových prostředích. V našem případě se <code>/bin/su</code> nepoužívá k typickému zvyšování práv na roota, např. kvůli instalaci nového softwaru, ale přesně naopak, tedy ke snížení práv spouštěného procesu, aby Kafka neběžela pod rootem. Pojďme zkusit najít v <code>/bin/su</code> odpověď na naši otázku.</p>


<div class="side">
<p>Anketa: Opravdu zabíjí <code>/bin/su</code> proces potomka signálem <code>SIGKILL</code>?</p>

<ul>
<li>Ano.</li>
<li>Ne.</li>
<li>Jiné.</li>
<li>Nevím.</li>
</ul>

<p>Správnou odpověď naleznete dále v textu a - ať už jste hlasovali jakkoli - nejspíš vás překvapí...</p>
</div>


<h2>Do hlubin <code>/bin/su</code></h2>

<p>Zkusme si v rychlosti analyzovat chování <code>/bin/su</code> a skriptů, které startují Kafku. <code>/bin/su</code> podle dokumentace nejdříve spouští shell a až ten následně aplikaci. Místo Kafky pro jednoduchost použijeme příkaz <code>sleep</code>, který čeká daný počet sekund a pak se sám ukončí. V prvním terminálu pod <code>root</code>em spustíme příkaz obdobný Upstart konfiguraci, přepínáme se na uživatele <code>nobody</code>. Příkaz <code>exec</code> se před <code>sleep</code> nachází úmyslně, JVM se při startu Kafky spouští úplně stejně (viz kód skriptů <code>kafka-server-start.sh</code> a <code>kafka-run-class.sh</code>).</p>

<pre>
# Become root
su -

# Lower privileges and execute something
exec /bin/su -s /bin/sh - nobody -c 'exec /bin/sleep 60'
</pre>

<p>V druhém terminálu se podíváme na strom procesů. Oba příkazy <code>/bin/su</code> se podle očekávání zachovaly, <code>exec</code> nahradil pouze proces shellu. Tímto pokusem jsme zjistili, že Upstart posílá ukončovací signály <code>/bin/su</code> a ne JVM, ve kterém běží Kafka, protože vidí a spravuje pouze přímé potomky. Našli jsme první, méně významný, bug. Je jisté, že <code>/bin/su</code> nikdy nepřepošle <code>SIGKILL</code>, který není mapovatelný, a Kafka může při ukončování zůstat "viset" nedefinovaně dlouho.</p>

<pre>
pstree | less

# After first su
init-+
     |-xterm---bash---su---bash

# After second su
init-+
     |-xterm---bash---su---su---sleep
</pre>

<p>Pokus číslo dva a <code>strace</code>. Jaká volání systému vykoná <code>/bin/su</code> po příchozím <code>SIGTERM</code>u?</p>

<pre>
strace /bin/su -s /bin/sh - nobody -c 'exec /bin/sleep 60' 2> strace_su.log

kill -s TERM 11827
</pre>

<p>V logu hledáme klíčová slova <code>kill</code>, <code>SIGTERM</code> a <code>SIGKILL</code>, které nás nejvíce zajímají. <code>/bin/su</code> nejdříve pošle potomkovi <code>SIGTERM</code>, poté počká 2 sekundy a aby mělo jistotu, zabije ho ještě pomocí <code>SIGKILL</code>. V rukách konečně máme jednoznačný důkaz, že <code>/bin/su</code> posílá i <code>SIGKILL</code>. Koruptované indexy se všemi dalšími potížemi jsou konečně vysvětleny! Nicméně se objevila další důležitá otázka: <strong>Kde se vzaly ty dvě sekundy</strong>? Tohle nemá Kafka šanci stihnout.</p>

<pre>
...
--- SIGTERM {si_signo=SIGTERM, si_code=SI_USER, si_pid=10805, si_uid=0} ---
rt_sigreturn()                          = -1 EINTR (Interrupted system call)
write(2, "\nSession terminated, killing she"..., 37
Session terminated, killing shell...) = 37
<span class="highlight">kill(11828, SIGTERM)                    = 0</span>
...
rt_sigprocmask(SIG_BLOCK, [CHLD], ~[INT QUIT KILL ALRM TERM STOP RTMIN RT_1], 8) = 0
<span class="highlight">nanosleep({2, 0}, 0x7ffc0c569e40)       = 0</span>
<span class="highlight">kill(11828, SIGKILL)                    = 0</span>
write(2, " ...killed.\n", 12 ...killed.
)           = 12
rt_sigaction(SIGTERM, {SIG_DFL, [], SA_RESTORER, 0x7f4d60a62660}, NULL, 8) = 0
kill(11827, SIGTERM)                    = 0
--- SIGTERM {si_signo=SIGTERM, si_code=SI_USER, si_pid=11827, si_uid=0} ---
+++ killed by SIGTERM +++
</pre>

<p>Pojďme se tedy ponořit ještě o trochu níž.</p>


<h2>Zdrojové kódy <code>/bin/su</code></h2>

<p>Najít zdrojové kódy <code>/bin/su</code> není úplně jednoduché, ale jde to zvládnout. Na našich serverech s Kafkou toho času běží stařičký CentOS 6.</p>

<pre>
rpm -qf /bin/su
coreutils-8.4-43.el6.x86_64
</pre>

<p>Po vyhledání balíčku a konkrétní verze dorazíme na <a href="https://rpmfind.net/linux/RPM/centos/6.8/x86_64/Packages/coreutils-8.4-43.el6.x86_64.html">rpmfind.net</a>, což sice není autoritativní zdroj, ale pro naše účely postačí. Na stránce je zároveň uveden odkaz na zdrojový balíček, ve kterém by se měly nacházet zdrojové kódy. Stáhneme ho a rozbalíme. Po chvíli hledání objevíme soubor <code>coreutils-pam.patch</code> a kód, který odpovídá výstupu <code>strace</code>.</p>

<pre>
+  if (caught) {
+    fprintf(stderr, "\nSession terminated, killing shell...");
<span class="highlight">+    kill (child, SIGTERM);</span>
+  }
+  /* Not checking retval on this because we need to call close session */
+  pam_setcred(pamh, PAM_DELETE_CRED | PAM_SILENT);
+  retval = pam_close_session(pamh, 0);
+  PAM_BAIL_P_VOID;
+  retval = pam_end(pamh, PAM_SUCCESS);
+  PAM_BAIL_P_VOID;
+  if (caught) {
<span class="highlight">+    sleep(2);</span>
<span class="highlight">+    kill(child, SIGKILL);</span>
+    fprintf(stderr, " ...killed.\n");
+    exit(-1);
+  }
</pre>

<p>Pravděpodobně se jedná o backport nějaké důležité funkcionality z upstreamu do starší verze, autorem patche je pravděpodobně někdo z RedHatu.</p>

<p>Výše uvedený <a href="https://rpmfind.net/linux/RPM/centos/6.8/x86_64/Packages/coreutils-8.4-43.el6.x86_64.html">rpmfind.net</a> uvádí jako zdroj <a href="http://www.gnu.org/software/coreutils/coreutils.html">gnu.org/coreutils</a>, nicméně projekt nebo jeho část se někdy v minulosti přesunul na <a href="https://git.kernel.org/pub/scm/utils/util-linux/util-linux.git/about/">kernel.org/util-linux</a>. S <code>git annotate</code> se dá v dávné historii dohledat <a href="https://github.com/karelzak/util-linux/commit/8171142ab66e94a409224547b33381259a0c3f72">původní zdrojový commit</a>, bohužel jeho popis neobsahuje moc relevantních informací. Pro zájemce uvádím i odkaz na <a href="https://github.com/karelzak/util-linux/blob/master/login-utils/su-common.c">zdrojový kód nejnovější verze <code>/bin/su</code></a>.</p>

<pre>
commit 8171142ab66e94a409224547b33381259a0c3f72
Author: Ludwig Nussel &lt;ludwig.nussel@suse.de&gt;
Date:   Tue Aug 17 13:21:44 2010 +0200

    pam support for su
</pre>

<p>Tento bug (nebo možná pouze feature) jsme samozřejmě poctivě <a href="https://github.com/karelzak/util-linux/issues/443">nahlásili</a> a dokonce i <a href="https://github.com/karelzak/util-linux/pull/444">opravili</a>. Po diskuzi s vývojáři (zdravíme Karla Žáka) to ale nevypadá, že by naše úprava byla někdy aplikována. Ačkoli změna oproti současnému stavu dává smysl, protože by se <code>/bin/su</code> chovalo konzistentněji, nemáme motivaci se ji pokusit protlačit.</p>


<h2>Není su jako su</h2>

<p>Nyní v článku trochu odbočíme a budeme se věnovat jednomu překvapivému zjištění. Pokud byste si zkusili výše uvedené příklady na Debianu, budou se chovat odlišně. Výstup <code>strace</code> od pohledu vypadá úplně jinak a hlavně neobsahuje žádný <code>SIGKILL</code>.</p>

<pre>
...
--- SIGTERM {si_signo=SIGTERM, si_code=SI_USER, si_pid=30289, si_uid=0} ---
rt_sigreturn()                          = -1 EINTR (Interrupted system call)
write(2, "\n", 1
)                       = 1
open("/usr/share/locale/locale.alias", O_RDONLY|O_CLOEXEC) = 7
fstat(7, {st_mode=S_IFREG|0644, st_size=2492, ...}) = 0
mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f5f5e7dc000
read(7, "# Locale name alias data base.\n#"..., 4096) = 2492
read(7, "", 4096)                       = 0
close(7)                                = 0
munmap(0x7f5f5e7dc000, 4096)            = 0
open("/usr/share/locale/en_US/LC_MESSAGES/shadow.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
open("/usr/share/locale/en/LC_MESSAGES/shadow.mo", O_RDONLY) = -1 ENOENT (No such file or directory)
write(2, "Session terminated, terminating "..., 40Session terminated, terminating shell...) = 40
<span class="highlight">kill(4294936960, SIGTERM)               = 0</span>
rt_sigaction(SIGALRM, {0x55b0bac7ef90, [ALRM], SA_RESTORER|SA_RESTART, 0x7f5f5de3d0e0}, {SIG_DFL, [], SA_RESTORER, 0x7f5f5de3d0e0}, 8) = 0
rt_sigaction(SIGCHLD, {0x55b0bac7ef30, [CHLD], SA_RESTORER|SA_RESTART, 0x7f5f5de3d0e0}, {SIG_DFL, [], 0}, 8) = 0
alarm(2)                                = 0
rt_sigprocmask(SIG_BLOCK, [ALRM], NULL, 8) = 0
wait4(30336, [{WIFSIGNALED(s) && WTERMSIG(s) == SIGTERM}], WNOHANG, NULL) = 30336
rt_sigprocmask(SIG_UNBLOCK, [ALRM], NULL, 8) = 0
write(2, " ...terminated.\n", 16 ...terminated.
)       = 16
...
exit_group(143)                         = ?
+++ exited with 143 +++
</pre>

<p>Může za to stáří systému? CentOS 6 je výrazně starší než taktéž hodně starý Debian Jessie a také jsme si ověřili, že se <code>SIGKILL</code> nachází i v master branchi <code>/bin/su</code>. Dokonce jsme udělali opravu, která tuto funkcionalitu odstraňuje. Nebo že by se jednalo o nějaký distribuční patch, který by opravoval právě tuto chybu? Možné je všechno. Opověď opět určitě nalezneme ve zdrojových kódech.</p>

<pre>
dpkg -S /bin/su
login: /bin/su
</pre>

<p>Balíček má jiné jméno (<a href="https://packages.debian.org/jessie/login">login</a>) a zdrojový balíček je také jiný (<a href="https://packages.debian.org/jessie/login">shadow</a>). Chyba v matrixu? Proč taková výrazná změna? Tentokrát nebudeme napínat, <strong><code>/bin/su</code> na Debianu je úplně jiná aplikace než <code>/bin/su</code> na CentOSu!</strong></p>

<p>Vstřebali jste tu informaci? Dobře, tak zavřete pusu. Debianí projekt sídlí na <a href="http://pkg-shadow.alioth.debian.org/">pkg-shadow.alioth.debian.org</a> a moc toho o sobě neříká. Vývojáři Debianu se možná rozhodli pro vlastní implementaci tohoto důležitého subsystému, aby ho měli plně pod kontrolou. Ale to jenom hádáme.</p>

<p>Jak jsme na něco takového přišli? Poté, co kolega objevil příčinu problému v <code>/bin/su</code>, zkusil jsem při psaní retrospektivy najít poslaný kousek kódu v upstream zdrojových kódech. A protože mám u sebe na počítači Debian, hledal jsem jiným směrem a došel do jiného cíle. Jedním slovem <em>náhoda</em>.</p>


<h2>Jak z toho ven?</h2>

<p>Vraťme se zpět k našemu problému a především k možnostem jeho řešení. Je jasné, že patchovat a provozovat vlastní verzi <code>/bin/su</code> není něco, do čeho by se komukoli chtělo. Nicméně použití tohoto nástroje byla čistě naše volba a nikdo nás do něho nenutí.</p>


<h3>su, sudo</h3>

<p>Co je vlastně v této situaci hlavním nedostatkem <code>/bin/su</code>? Především to, že s ním vzniká hned několik podprocesů a že Upstart operuje s PID předka místo potomka. Nejdříve se spouští <code>/bin/su</code>, <code>/bin/su</code> spouští shell a shell spouští požadovaný příkaz. Při ukončování procesu Upstart posílá <code>SIGTERM</code> <code>/bin/su</code> a ne Kafce. Tato sekvence několika fork-exec operací je výrazně složitější, než by mohla být. Místo ní by úplně stačilo přepnout efektivní UID z roota na neprivilegovaného uživatele a následně zavolat exec, který by přepsal současný obsah procesu spouštěnou aplikací. Jednoho by mohl napadnout alternativní příkaz sudo, ten se však chová obdobně a výsledná situace by byla naprosto stejná. Ani jeden z nich se pro tento use case naprosto nehodí, nebyly na něj navrženy, a je tedy zbytečné je dále uvažovat.</p>


<h3>Upstart</h3>

<p>Úplně nejjednodušší by bylo pomocí direktivy <a href="http://upstart.ubuntu.com/cookbook/#setuid"><code>setuid &lt;username&gt;</code></a> požádat Upstart, aby špinavou práci s přepínáním uživatele odvedl sám a nás tím vůbec nezatěžoval. Bohužel tato možnost je dostupná až od verze 1.4, kdežto v CentOSu 6 se nachází pouze výrazně starší 0.6.5. Aktualizace kvůli podobné maličkosti tak zůstává pouze v říši fantazie.</p>

<p>Dokumentace Upstartu popisuje, jak správně <a href="http://upstart.ubuntu.com/cookbook/#run-a-job-as-a-different-user">spustit úlohu pod jiným uživatelem</a>. Jako jednu z doporučovaných možností uvádí utilitu <code>start-stop-daemon</code> dostupnou např. v Debianu a Ubuntu, která "jednoduše spustí daný příkaz poté, co změní UID/GID (exec bez forku)", což je přesně to, k čemu jsme oklikou došli sami. U <code>su</code> a <code>sudo</code> uvádí další dosud neuvažovanou nevýhodu a to, že skrze PAM zapisují záznamy o přihlašování uživatele do <code>wtmp</code>, což je při obyčejném spouštění aplikace spíše nežádoucí chování. Téměř na konci této sekce dokumentace je mezi příklady se <code>su</code> a <code>sudo</code> jakoby mimochodem zmíněna direktiva <code>expect</code>.</p>

<p><a href="http://upstart.ubuntu.com/cookbook/#expect">Popis <code>expect</code></a> je uveden rámečkem s varováním "extrémně důležitá direktiva: čtěte tuto sekci pozorně". Následuje několik odstavců o tom, jak se chovají různé typy aplikací. Některé neforkují vůbec, jiné forkují jednou a ještě jiné dvakrát a co z toho všeho plyne pro Upstart, který musí být schopen referencovat a spravovat správný process. Kdybychom si tuto část přečetli už kdysi, ušetřili bychom si všechny budoucí zážitky a problémy. S původní <code>/bin/su</code> variantou v konfiguračním souboru by bylo správné přidat dodatečný řádek <code>expect fork</code>, který by Upstartu oznámil, že má čekat právě jeden fork spouštěné aplikace. Tudíž by nespravoval <code>/bin/su</code>, ale Kafku/JVM. Tuto možnost jsme už ovšem nezkoušeli, protože jsme se rozhodli jít dříve naznačenou cestou.</p>


<h3>Přepnutí uživatele</h3>

<p>Vraťme se k Debianímu <code>start-stop-daemon</code>, který bohužel na CentOSu není dostupný, a jeho alternativám. Je překvapivé zjistit, že nejspíš neexistuje žádný univerzálně dostupný nástroj a že každá distribuce poskytuje ve výchozí instalaci něco jiného a nekompatibilního. Nástroje mají jiná jména, jiné parametry a jiné možnosti. Konfigurační soubor Upstartu by nebyl přenositelný mezi Linuxovými distribucemi (pokud pomineme fakt dostupnosti samotného Upstartu v distribucích). Samozřejmě všechno se dá nějakým způsobem doinstalovat, třeba i velice jednoduše, ale kdo by se o to chtěl starat. Tato situace se může porovnat například se <code>su</code> a <code>sudo</code> - dá se na ně spolehnout, že budou dostupné tak nějak vždycky a všude. Vzájemně nekompatibilních možností je mnoho:</p>

<ul>
<li><code>start-stop-daemon</code> - pouze Debian a jeho deriváty</li>
<li><code>daemon</code> utilita z <code>/etc/init.d/functions</code> - různě po webu doporučovaná CentOS alternativa ke <code>start-stop-daemon</code></li>
<li>další <a href="https://github.com/daleobrien/start-stop-daemon"><code>start-stop-daemon</code></a> - přepis Debianího toolu z Perlu do C</li>
<li><a href="https://git.kernel.org/pub/scm/utils/util-linux/util-linux.git/tree/sys-utils/setpriv.c"><code>setpriv</code></a> - součást util-linux, <a href="https://github.com/karelzak/util-linux/issues/443#issuecomment-304610565">zmíněný v diskuzi u reportu o chybě v <code>/bin/su</code></a>, ale není ani v CentOSu ani v Debianu</li>
<li><a href="https://github.com/tianon/gosu">gosu</a> - používaný v kontejnerech a Docker světě</li>
<li>Python: <code><a href="https://docs.python.org/3/library/os.html">import os</a> ; os.setuid(...) ; os.exec*(...)</code>. Při použití pozor na <a href="https://www.dwheeler.com/secure-programs/Secure-Programs-HOWTO/environment-variables.html">reset prostředí</a>!</li>
<li>A spousty dalších možností...</li>
</ul>

<p>Aby jich nebylo málo, shodou okolností máme vlastní nástroj <code>ff-runner</code>, který byl před lety vytvořen ke standartizaci spouštění našich serverových aplikací. Jednou z jeho vlastností je mimo jiné přepnutí na požadovaného uživatele a exec procesu (bez forku), už ho máme na serverech, takže volba byla celkem jasná.</p>


<h2>Závěrem</h2>

<p>Nebylo to nijak jednoduché, ale chybu s problematickými restarty Kafky jsme nakonec úspěšně vyřešili. Při hledání jsme se ponořili z vícedatacentrového cloudu s několika distribuovanými aplikacemi o mnoha instancích na úroveň operačního systému, dokumentace Kafky, jejích startovacích skriptů, JVM, systémových init skriptů a dále až k teoretickému chování unixových procesů při jejich spouštění.</p>

<p>Jádro celého problému jsme nakonec odhalili až ve zdrojových kódech příkazu <code>/bin/su</code>, kam nás navedl <code>strace</code> výpis systémových volání. <code>/bin/su</code> obsahuje nedokumentovanou a velice nečekanou vlastnost, dvě sekundy od <code>SIGTERM</code> požadavku na ukončení posílá procesu potomka signál <code>SIGKILL</code> a tím mu bere jakoukoli šanci na korektní ukončení. Nicméně toto tvrzení neplatí ve všech Linuxových distribucích! Další překvapení přišlo ve chvíli, kdy jsme zjistili, že <code>/bin/su</code> na CentOSu a <code>/bin/su</code> na Debianu jsou dvě různé, naprosto nezávislé aplikace s různými zdrojovými kódy.</p>

<p>Dále explicitně podotýkáme, že ani při hledání chyby a ani při psaní článku nebyly prováděny žádné pokusy na kafkách či jiných zvířatech spojené s jejich případným týráním.</p>

</div>
</body>
</html>
